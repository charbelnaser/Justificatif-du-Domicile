{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificatif Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "#Add Callbacks, e.g. ModelCheckpoints, earlystopping, csvlogger.\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import ImageEnhance, ImageFilter,Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1500\n",
    "aspect_ratio = 1.5\n",
    "INPUT_SHAPE = (SIZE, int(SIZE*aspect_ratio), 3)\n",
    "# INPUT_SHAPE = (1240, 1240, 3)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# plot_model(model, to_file='model_architecture.png', show_shapes=True)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def straighten_image(pil_image):\n",
    "    try:\n",
    "        # cv_image = np.array(pil_image)\n",
    "        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_BGR2RGB)\n",
    "        # Convert to gray\n",
    "        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Threshold the image\n",
    "        _, threshold_image = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Perform morphological opening\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        threshold_image = cv2.morphologyEx(threshold_image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Perform morphological closing\n",
    "        threshold_image = cv2.morphologyEx(threshold_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Threshold the image again\n",
    "        _, threshold_image = cv2.threshold(threshold_image, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "        # Find contours\n",
    "        contours, hierarchy = cv2.findContours(threshold_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[0:10]\n",
    "\n",
    "        # Get the largest contour\n",
    "        largest_contour = contours[1]\n",
    "        image_area = cv_image.shape[0] * cv_image.shape[1]\n",
    "        contour_area = cv2.contourArea(largest_contour)\n",
    "        # Calculate the proportion of the contour area compared to the image area\n",
    "        proportion = contour_area / image_area\n",
    "        if proportion <= 0.3:\n",
    "            pil_image = Image.fromarray(straightened_invoice)\n",
    "            return  pil_image\n",
    "\n",
    "        # Contour detection\n",
    "        # cv2.drawContours(cv_image, [largest_contour], -1, (0, 255, 0), 2)\n",
    "        # Find the convex hull of the contour\n",
    "        hull = cv2.convexHull(largest_contour)\n",
    "        input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "        # Find the extreme points of the convex hull\n",
    "        leftmost = tuple(hull[hull[:, :, 0].argmin()][0])\n",
    "        rightmost = tuple(hull[hull[:, :, 0].argmax()][0])\n",
    "        topmost = tuple(hull[hull[:, :, 1].argmin()][0])\n",
    "        bottommost = tuple(hull[hull[:, :, 1].argmax()][0])\n",
    "        bottom_right , top_right , top_left , bottom_left = None, None, None, None\n",
    "        \n",
    "        # Sort the extreme points\n",
    "        extreme_points = [leftmost, rightmost, topmost, bottommost]\n",
    "        sorted_points = sorted(extreme_points, key=lambda x: (x[0], x[1]))\n",
    "\n",
    "        sorted_points = sorted(sorted_points, key=lambda p: p[0])\n",
    "        left_points = sorted_points[:2]\n",
    "        min_y_point = min(left_points, key=lambda p: p[1])\n",
    "        top_left = min_y_point\n",
    "        for point in left_points:\n",
    "            if point != min_y_point:\n",
    "                bottom_left = point\n",
    "                break\n",
    "    \n",
    "        right_points = sorted(sorted_points, key=lambda p: p[0], reverse=True)[:2]\n",
    "        top_right = min(right_points, key=lambda p: p[1])\n",
    "\n",
    "        for point in right_points:\n",
    "            if point != top_right:\n",
    "                bottom_right = point\n",
    "                break\n",
    "        if bottom_right and top_right and top_left and bottom_left:\n",
    "            rect = cv2.minAreaRect(largest_contour)\n",
    "            # Top-left corner: (0, 0)\n",
    "            # Top-right corner: (img.shape[1], 0)\n",
    "            # Bottom-right corner: (img.shape[1], img.shape[0])\n",
    "            # Bottom-left corner: (0, img.shape[0])\n",
    "            # Define the target rectangle corners\n",
    "            target_corners = np.array([[0, 0], [cv_image.shape[1], 0], [cv_image.shape[1], cv_image.shape[0]], [0, cv_image.shape[0]]], dtype=np.float32)\n",
    "\n",
    "            # Define the source rectangle corners\n",
    "            source_corners = np.array([top_left, top_right, bottom_right, bottom_left], dtype=np.float32)\n",
    "\n",
    "\n",
    "            # new_source_corners = np.array([top_left, bottom_left, bottom_right, top_right], dtype=np.float32)\n",
    "\n",
    "            transformation_matrix, _ = cv2.findHomography(source_corners, target_corners,cv2.RANSAC,5.0)\n",
    "            straightened_invoice = cv2.warpPerspective(cv_image, transformation_matrix, (cv_image.shape[1], cv_image.shape[0]))\n",
    "            pil_image = Image.fromarray(straightened_invoice)\n",
    "\n",
    "            return pil_image\n",
    "        else:\n",
    "            # pil_image.show()\n",
    "\n",
    "            return pil_image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during image processing:\", str(e))\n",
    "        sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform image processing\n",
    "def image_processing(image):\n",
    "    try:\n",
    "        # Convert image to PIL Image\n",
    "        pil_image = Image.fromarray(np.uint8(image))\n",
    "        # pil_image.thumbnail(target_size, Image.LANCZOS)\n",
    "\n",
    "        # pil_image.show()\n",
    "        pil_image = pil_image.convert('RGB')\n",
    "        pil_image = straighten_image(pil_image)\n",
    "        # print(pil_image.size)\n",
    "        # Apply median filter\n",
    "        filtered_image = pil_image.filter(ImageFilter.MedianFilter(size=1))\n",
    "        # Apply sharpening\n",
    "        sharpened_image = filtered_image.filter(ImageFilter.SHARPEN)\n",
    "        # Enhance contrast\n",
    "        enhancer = ImageEnhance.Contrast(sharpened_image)\n",
    "        enhanced_image = enhancer.enhance(1.5)  # Increase contrast by a factor of 1.5\n",
    "        # Enhance brightness\n",
    "        enhancer = ImageEnhance.Brightness(enhanced_image)\n",
    "        final_image = enhancer.enhance(1.2)\n",
    "        # Apply Gaussian blur filter\n",
    "        pil_image = final_image.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "        # pil_image.show()\n",
    "        # Convert back to numpy array\n",
    "        numpy_image = np.array(pil_image)\n",
    "    \n",
    "        # Scale pixel values to [0, 1]\n",
    "        numpy_image = numpy_image / 255.0\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during image processing:\", str(e))\n",
    "        sys.exit()\n",
    "    return numpy_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 25\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = image_processing)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function = image_processing)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = image_processing)\n",
    "SIZE = 1500\n",
    "target_size = (SIZE,int(SIZE*aspect_ratio))\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train3',  # this is the input directory\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=target_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'validation3',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=target_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'test3',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=target_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.n//batch_size,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.n//batch_size)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred\", str(e))\n",
    "    sys.exit()\n",
    "# Evaluate the model on the test set\n",
    "    # test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.n//batch_size)\n",
    "    # print('Test accuracy:', test_acc)\n",
    "\n",
    "# Make predictions on the test set\n",
    "    # test_predictions = model.predict_generator(test_generator, steps=test_generator.n//batch_size)\n",
    "# Get the true labels and predicted labels for the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "model.save('my_model_4.h5')\n",
    "\n",
    "loaded_model = load_model('my_model_4.h5')\n",
    "\n",
    "\n",
    "# Get the true labels and predicted labels for the test data\n",
    "true_labels = test_generator.classes\n",
    "predicted_labels = loaded_model.predict_generator(test_generator).argmax(axis=1)\n",
    "\n",
    "# Compute the accuracy, precision, and recall\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "test_loss, test_acc = loaded_model.evaluate_generator(test_generator, steps=test_generator.n//batch_size)\n",
    "print('Test accuracy:', test_acc)\n",
    "# Print the results\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "\n",
    "# Print the ground truth and predicted labels for the first 10 images\n",
    "# print(\"Ground Truth Labels: \")\n",
    "# print([class_labels[np.argmax(label)] for label in test_labels[:10]])\n",
    "# print(\"\\nPredicted Labels: \")\n",
    "# print([class_labels[np.argmax(pred)] for pred in test_predictions[:10]])\n",
    "# fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(10, 20))\n",
    "# for i, ax in enumerate(axs.flatten()):\n",
    "#     if i < len(test_images):\n",
    "#         ax.imshow(test_images[i])\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(f\"Ground Truth: {class_labels[np.argmax(test_labels[i])]}, Predicted: {class_labels[np.argmax(test_predictions[i])]}\")\n",
    "#     else:\n",
    "#         ax.axis('off')\n",
    "# plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
