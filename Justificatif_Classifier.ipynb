{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificatif Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "#Add Callbacks, e.g. ModelCheckpoints, earlystopping, csvlogger.\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import ImageEnhance, ImageFilter,Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 127, 127, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 115200)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               29491456  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,618,116\n",
      "Trainable params: 29,618,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (256, 256, 3)\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIZE = 1500\n",
    "# aspect_ratio = 1.5\n",
    "# INPUT_SHAPE = (SIZE, int(SIZE*aspect_ratio), 3)\n",
    "# # INPUT_SHAPE = (1240, 1240, 3)\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(4))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# plot_model(model, to_file='model_architecture.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def straighten_image(pil_image):\n",
    "    try:\n",
    "        # cv_image = np.array(pil_image)\n",
    "        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_BGR2RGB)\n",
    "        # Convert to gray\n",
    "        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Threshold the image\n",
    "        _, threshold_image = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Perform morphological opening\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        threshold_image = cv2.morphologyEx(threshold_image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Perform morphological closing\n",
    "        threshold_image = cv2.morphologyEx(threshold_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Threshold the image again\n",
    "        _, threshold_image = cv2.threshold(threshold_image, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "        # Find contours\n",
    "        contours, hierarchy = cv2.findContours(threshold_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[0:10]\n",
    "\n",
    "        # Get the largest contour\n",
    "        largest_contour = contours[1]\n",
    "        image_area = cv_image.shape[0] * cv_image.shape[1]\n",
    "        contour_area = cv2.contourArea(largest_contour)\n",
    "        # Calculate the proportion of the contour area compared to the image area\n",
    "        proportion = contour_area / image_area\n",
    "        if proportion <= 0.3:\n",
    "            return  pil_image\n",
    "\n",
    "        # Contour detection\n",
    "        # cv2.drawContours(cv_image, [largest_contour], -1, (0, 255, 0), 2)\n",
    "        # Find the convex hull of the contour\n",
    "        hull = cv2.convexHull(largest_contour)\n",
    "        input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "        # Find the extreme points of the convex hull\n",
    "        leftmost = tuple(hull[hull[:, :, 0].argmin()][0])\n",
    "        rightmost = tuple(hull[hull[:, :, 0].argmax()][0])\n",
    "        topmost = tuple(hull[hull[:, :, 1].argmin()][0])\n",
    "        bottommost = tuple(hull[hull[:, :, 1].argmax()][0])\n",
    "        bottom_right , top_right , top_left , bottom_left = None, None, None, None\n",
    "        \n",
    "        # Sort the extreme points\n",
    "        extreme_points = [leftmost, rightmost, topmost, bottommost]\n",
    "        sorted_points = sorted(extreme_points, key=lambda x: (x[0], x[1]))\n",
    "\n",
    "        sorted_points = sorted(sorted_points, key=lambda p: p[0])\n",
    "        left_points = sorted_points[:2]\n",
    "        min_y_point = min(left_points, key=lambda p: p[1])\n",
    "        top_left = min_y_point\n",
    "        for point in left_points:\n",
    "            if point != min_y_point:\n",
    "                bottom_left = point\n",
    "                break\n",
    "    \n",
    "        right_points = sorted(sorted_points, key=lambda p: p[0], reverse=True)[:2]\n",
    "        top_right = min(right_points, key=lambda p: p[1])\n",
    "\n",
    "        for point in right_points:\n",
    "            if point != top_right:\n",
    "                bottom_right = point\n",
    "                break\n",
    "        if bottom_right and top_right and top_left and bottom_left:\n",
    "            rect = cv2.minAreaRect(largest_contour)\n",
    "            # Top-left corner: (0, 0)\n",
    "            # Top-right corner: (img.shape[1], 0)\n",
    "            # Bottom-right corner: (img.shape[1], img.shape[0])\n",
    "            # Bottom-left corner: (0, img.shape[0])\n",
    "            # Define the target rectangle corners\n",
    "            target_corners = np.array([[0, 0], [cv_image.shape[1], 0], [cv_image.shape[1], cv_image.shape[0]], [0, cv_image.shape[0]]], dtype=np.float32)\n",
    "\n",
    "            # Define the source rectangle corners\n",
    "            source_corners = np.array([top_left, top_right, bottom_right, bottom_left], dtype=np.float32)\n",
    "\n",
    "\n",
    "            # new_source_corners = np.array([top_left, bottom_left, bottom_right, top_right], dtype=np.float32)\n",
    "\n",
    "            transformation_matrix, _ = cv2.findHomography(source_corners, target_corners,cv2.RANSAC,5.0)\n",
    "            straightened_invoice = cv2.warpPerspective(cv_image, transformation_matrix, (cv_image.shape[1], cv_image.shape[0]))\n",
    "            pil_image = Image.fromarray(straightened_invoice)\n",
    "\n",
    "            return pil_image\n",
    "        else:\n",
    "            # pil_image.show()\n",
    "\n",
    "            return pil_image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during image processing:\", str(e))\n",
    "        sys.exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform image processing\n",
    "def image_processing(image):\n",
    "    try:\n",
    "        # Convert image to PIL Image\n",
    "        pil_image = Image.fromarray(np.uint8(image))\n",
    "        # pil_image.thumbnail(target_size, Image.LANCZOS)\n",
    "\n",
    "        # pil_image.show()\n",
    "        pil_image = pil_image.convert('RGB')\n",
    "        pil_image = straighten_image(pil_image)\n",
    "        # print(pil_image.size)\n",
    "        # Apply median filter\n",
    "        filtered_image = pil_image.filter(ImageFilter.MedianFilter(size=1))\n",
    "        # Apply sharpening\n",
    "        sharpened_image = filtered_image.filter(ImageFilter.SHARPEN)\n",
    "        # Enhance contrast\n",
    "        enhancer = ImageEnhance.Contrast(sharpened_image)\n",
    "        enhanced_image = enhancer.enhance(1.5)  # Increase contrast by a factor of 1.5\n",
    "        # Enhance brightness\n",
    "        enhancer = ImageEnhance.Brightness(enhanced_image)\n",
    "        final_image = enhancer.enhance(1.2)\n",
    "        # Apply Gaussian blur filter\n",
    "        pil_image = final_image.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "        # pil_image.show()\n",
    "        # Convert back to numpy array\n",
    "        numpy_image = np.array(pil_image)\n",
    "    \n",
    "        # Scale pixel values to [0, 1]\n",
    "        numpy_image = numpy_image / 255.0\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred during image processing:\", str(e))\n",
    "        sys.exit()\n",
    "    return numpy_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4857 images belonging to 4 classes.\n",
      "Found 1938 images belonging to 4 classes.\n",
      "Found 1950 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 25\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = image_processing)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function = image_processing)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = image_processing)\n",
    "SIZE = 256\n",
    "aspect_ratio = 1\n",
    "target_size = (SIZE,int(SIZE*aspect_ratio))\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train3',  # this is the input directory\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=target_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'validation3',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=target_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'test3',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=target_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charbel.nasr\\AppData\\Local\\Temp\\ipykernel_24544\\454017111.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "151/151 [==============================] - 689s 5s/step - loss: 1.3229 - accuracy: 0.5691 - val_loss: 0.7138 - val_accuracy: 0.7297\n",
      "Epoch 2/25\n",
      "151/151 [==============================] - 915s 6s/step - loss: 0.2906 - accuracy: 0.9115 - val_loss: 0.0860 - val_accuracy: 0.9781\n",
      "Epoch 3/25\n",
      "151/151 [==============================] - 783s 5s/step - loss: 0.4581 - accuracy: 0.9691 - val_loss: 0.0739 - val_accuracy: 0.9839\n",
      "Epoch 4/25\n",
      "151/151 [==============================] - 728s 5s/step - loss: 0.0158 - accuracy: 0.9934 - val_loss: 0.1650 - val_accuracy: 0.9839\n",
      "Epoch 5/25\n",
      "151/151 [==============================] - 679s 5s/step - loss: 0.1458 - accuracy: 0.9809 - val_loss: 0.0788 - val_accuracy: 0.9802\n",
      "Epoch 6/25\n",
      "151/151 [==============================] - 662s 4s/step - loss: 0.1206 - accuracy: 0.9890 - val_loss: 0.0984 - val_accuracy: 0.9844\n",
      "Epoch 7/25\n",
      "151/151 [==============================] - 662s 4s/step - loss: 0.0463 - accuracy: 0.9907 - val_loss: 0.2197 - val_accuracy: 0.9833\n",
      "Epoch 8/25\n",
      "151/151 [==============================] - 639s 4s/step - loss: 0.0304 - accuracy: 0.9965 - val_loss: 0.1482 - val_accuracy: 0.9823\n",
      "Epoch 9/25\n",
      "151/151 [==============================] - 571s 4s/step - loss: 0.0268 - accuracy: 0.9948 - val_loss: 0.1024 - val_accuracy: 0.9818\n",
      "Epoch 10/25\n",
      "151/151 [==============================] - 602s 4s/step - loss: 0.0632 - accuracy: 0.9954 - val_loss: 0.2706 - val_accuracy: 0.9828\n",
      "Epoch 11/25\n",
      "151/151 [==============================] - 570s 4s/step - loss: 1.6484 - accuracy: 0.9921 - val_loss: 0.2232 - val_accuracy: 0.9828\n",
      "Epoch 12/25\n",
      "151/151 [==============================] - 562s 4s/step - loss: 0.7065 - accuracy: 0.9911 - val_loss: 0.6230 - val_accuracy: 0.9792\n",
      "Epoch 13/25\n",
      "151/151 [==============================] - 552s 4s/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.4869 - val_accuracy: 0.9823\n",
      "Epoch 14/25\n",
      "151/151 [==============================] - 864s 6s/step - loss: 0.6008 - accuracy: 0.9872 - val_loss: 0.2440 - val_accuracy: 0.9854\n",
      "Epoch 15/25\n",
      "151/151 [==============================] - 606s 4s/step - loss: 0.1722 - accuracy: 0.9886 - val_loss: 0.2456 - val_accuracy: 0.9839\n",
      "Epoch 16/25\n",
      "151/151 [==============================] - 553s 4s/step - loss: 7.0069e-05 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9865\n",
      "Epoch 17/25\n",
      "151/151 [==============================] - 582s 4s/step - loss: 2.5330e-07 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9828\n",
      "Epoch 18/25\n",
      "151/151 [==============================] - 587s 4s/step - loss: 1.0265e-07 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9839\n",
      "Epoch 19/25\n",
      "151/151 [==============================] - 707s 5s/step - loss: 3.7430e-08 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9833\n",
      "Epoch 20/25\n",
      "151/151 [==============================] - 576s 4s/step - loss: 2.7819e-08 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9833\n",
      "Epoch 21/25\n",
      "151/151 [==============================] - 652s 4s/step - loss: 2.4237e-08 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9828\n",
      "Epoch 22/25\n",
      "151/151 [==============================] - 735s 5s/step - loss: 2.1223e-08 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9828\n",
      "Epoch 23/25\n",
      "151/151 [==============================] - 648s 4s/step - loss: 1.9123e-08 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9828\n",
      "Epoch 24/25\n",
      "151/151 [==============================] - 651s 4s/step - loss: 1.7270e-08 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.9828\n",
      "Epoch 25/25\n",
      "151/151 [==============================] - 698s 5s/step - loss: 1.5886e-08 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.n//batch_size,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.n//batch_size)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred\", str(e))\n",
    "    sys.exit()\n",
    "# Evaluate the model on the test set\n",
    "    # test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.n//batch_size)\n",
    "    # print('Test accuracy:', test_acc)\n",
    "\n",
    "# Make predictions on the test set\n",
    "    # test_predictions = model.predict_generator(test_generator, steps=test_generator.n//batch_size)\n",
    "# Get the true labels and predicted labels for the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charbel.nasr\\AppData\\Local\\Temp\\ipykernel_24544\\3402059730.py:9: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predicted_labels = loaded_model.predict_generator(test_generator).argmax(axis=1)\n",
      "C:\\Users\\charbel.nasr\\AppData\\Local\\Temp\\ipykernel_24544\\3402059730.py:15: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_loss, test_acc = loaded_model.evaluate_generator(test_generator, steps=test_generator.n//batch_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9885416626930237\n",
      "Accuracy: 0.9882051282051282\n",
      "Precision: 0.9895040421297358\n",
      "Recall: 0.9882051282051282\n"
     ]
    }
   ],
   "source": [
    "# Save your model\n",
    "model.save('my_model_5.h5')\n",
    "\n",
    "loaded_model = load_model('my_model_5.h5')\n",
    "\n",
    "\n",
    "# Get the true labels and predicted labels for the test data\n",
    "true_labels = test_generator.classes\n",
    "predicted_labels = loaded_model.predict_generator(test_generator).argmax(axis=1)\n",
    "\n",
    "# Compute the accuracy, precision, and recall\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "test_loss, test_acc = loaded_model.evaluate_generator(test_generator, steps=test_generator.n//batch_size)\n",
    "print('Test accuracy:', test_acc)\n",
    "# Print the results\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "\n",
    "# Print the ground truth and predicted labels for the first 10 images\n",
    "# print(\"Ground Truth Labels: \")\n",
    "# print([class_labels[np.argmax(label)] for label in test_labels[:10]])\n",
    "# print(\"\\nPredicted Labels: \")\n",
    "# print([class_labels[np.argmax(pred)] for pred in test_predictions[:10]])\n",
    "# fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(10, 20))\n",
    "# for i, ax in enumerate(axs.flatten()):\n",
    "#     if i < len(test_images):\n",
    "#         ax.imshow(test_images[i])\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(f\"Ground Truth: {class_labels[np.argmax(test_labels[i])]}, Predicted: {class_labels[np.argmax(test_predictions[i])]}\")\n",
    "#     else:\n",
    "#         ax.axis('off')\n",
    "# plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
